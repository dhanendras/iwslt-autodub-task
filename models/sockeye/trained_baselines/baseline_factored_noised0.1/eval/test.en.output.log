[2023-09-04:10:43:28:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.1.34, commit 4c30942ddb523533bccb4d2cbb3e894e45b1db93, path /home/dhanendra/anaconda3/lib/python3.11/site-packages/sockeye/__init__.py
[2023-09-04:10:43:28:INFO:sockeye.utils:log_torch_version] PyTorch: 1.13.1+cu117 (/home/dhanendra/anaconda3/lib/python3.11/site-packages/torch/__init__.py)
[2023-09-04:10:43:28:INFO:sockeye.utils:log_basic_info] Command: /home/dhanendra/anaconda3/bin/sockeye-translate -i processed_datasets/de-text-noisy-durations0.1-en-phones-durations/test.de.json -o models/sockeye/trained_baselines/baseline_factored_noised0.1/eval/test.en.output --models models/sockeye/trained_baselines/baseline_factored_noised0.1/model --checkpoints 78 -b 5 --batch-size 32 --chunk-size 20000 --output-type translation_with_factors --max-output-length 768 --json-input --quiet
[2023-09-04:10:43:28:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(config=None, input='processed_datasets/de-text-noisy-durations0.1-en-phones-durations/test.de.json', input_factors=None, json_input=True, output='models/sockeye/trained_baselines/baseline_factored_noised0.1/eval/test.en.output', models=['models/sockeye/trained_baselines/baseline_factored_noised0.1/model'], checkpoints=[78], nbest_size=1, beam_size=5, greedy=False, beam_search_stop='all', batch_size=32, chunk_size=20000, sample=None, seed=None, ensemble_mode='linear', bucket_width=10, max_input_length=None, max_output_length_num_stds=2, max_output_length=768, restrict_lexicon=None, restrict_lexicon_topk=None, skip_nvs=False, nvs_thresh=0.5, strip_unknown_words=False, prevent_unk=False, output_type='translation_with_factors', length_penalty_alpha=1.0, length_penalty_beta=0.0, brevity_penalty_type='none', brevity_penalty_weight=1.0, brevity_penalty_constant_length_ratio=0.0, dtype=None, clamp_to_dtype=False, device_id=0, use_cpu=False, env=None, tf32=True, quiet=True, quiet_secondary_workers=False, no_logfile=False, loglevel='INFO', loglevel_secondary_workers='INFO', knn_index=None, knn_lambda=0.8)
[2023-09-04:10:43:28:INFO:sockeye.utils:init_device] CUDA not available, defaulting to CPU device
[2023-09-04:10:43:28:INFO:sockeye.translate:run_translate] Translate Device: cpu
[2023-09-04:10:43:28:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models/sockeye/trained_baselines/baseline_factored_noised0.1/model'] ...
[2023-09-04:10:43:28:INFO:sockeye.vocab:vocab_from_json] Vocabulary (10344 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.src.0.json"
[2023-09-04:10:43:28:INFO:sockeye.vocab:vocab_from_json] Vocabulary (80 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.0.json"
[2023-09-04:10:43:28:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.1.json"
[2023-09-04:10:43:28:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.2.json"
[2023-09-04:10:43:28:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.3.json"
[2023-09-04:10:43:28:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.4.json"
[2023-09-04:10:43:28:INFO:sockeye.model:load_model] Model version: 3.1.27
[2023-09-04:10:43:28:INFO:sockeye.model:load_config] Loaded model config from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/config"
[2023-09-04:10:43:28:INFO:sockeye.model:load_model] Disabling dropout layers for performance reasons
[2023-09-04:10:43:28:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=2890740, num_discarded=0, num_tokens_source=59369190, num_tokens_target=155336450, num_unks_source=0, num_unks_target=0, max_observed_len_source=94, max_observed_len_target=189, size_vocab_source=10344, size_vocab_target=80, length_ratio_mean=2.6285491632178375, length_ratio_std=0.5307655732772438, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (151, 152), (151, 160), (151, 168), (151, 176), (151, 184), (151, 192), (151, 200), (151, 201)], num_sents_per_bucket=[0, 22110, 135360, 246550, 350520, 403580, 430220, 432370, 393550, 273340, 135700, 50610, 13540, 2600, 320, 170, 80, 40, 40, 10, 20, 0, 0, 10, 0, 0], average_len_target_per_bucket=[None, 14.639077340569925, 21.061391843971673, 28.75895355911596, 36.678905625926355, 44.57116309034136, 52.536074566501156, 60.483960496795376, 68.38394104942114, 76.15284993048971, 83.90117907148164, 91.77376012645728, 99.63367799113755, 107.29230769230787, 115.21874999999991, 124.94117647058823, 132.62499999999997, 139.5, 147.24999999999997, 159.0, 165.0, None, None, 189.0, None, None], length_ratio_stats_per_bucket=[(None, None), (1.6336605602548555, 0.286261936883669), (1.9424967481218725, 0.34652802807048444), (2.2378038095453197, 0.3976252139444698), (2.440769792284621, 0.43440989413337183), (2.5843426768893876, 0.4541766109606066), (2.687728476890013, 0.47428305790760306), (2.7666510787767975, 0.48227906550526356), (2.8217258334504756, 0.48470162974307845), (2.8759974432299935, 0.49482087161470556), (2.933253154965025, 0.5004821684234914), (2.9835199293468997, 0.5201429624681303), (3.0325299451010497, 0.5067356869273223), (2.992097700547769, 0.48118416764844135), (2.9725602658980277, 0.531975485592598), (3.029502354582931, 0.6547038619502166), (3.2535635605818016, 0.4859033383112516), (3.475107493857494, 0.15279703105488074), (3.1417111847962915, 0.250628449935598), (3.3125, 0.0), (2.8999999999999995, 0.40000000000000013), (None, None), (None, None), (3.0, 0.0), (None, None), (None, None)]), max_seq_len_source=151, max_seq_len_target=201, num_source_factors=1, num_target_factors=5, eop_id=-1), vocab_source_size=10344, vocab_target_size=80, config_embed_source=EmbeddingConfig(vocab_size=10344, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=False), config_embed_target=EmbeddingConfig(vocab_size=80, num_embed=512, dropout=0.0, num_factors=5, factor_configs=[FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False), FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False), FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False), FactorConfig(vocab_size=9008, num_embed=32, combine='concat', share_embedding=False)], allow_sparse_grad=False), config_encoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=151, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=512, use_glu=False), config_decoder=TransformerConfig(model_size=736, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=151, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=512, use_glu=False), config_length_task=None, weight_tying_type='none', lhuc=False, dtype='float32', neural_vocab_selection=None, neural_vocab_selection_block_loss=False)
[2023-09-04:10:43:35:INFO:sockeye.model:load_parameters] Loaded params from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/params.00078" to "cpu"
[2023-09-04:10:43:35:INFO:sockeye.model:load_model] Model dtype: torch.float32
[2023-09-04:10:43:35:INFO:sockeye.model:load_models] 1 model(s) loaded in 6.7443s
[2023-09-04:10:43:35:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=5 algorithm=BeamSearch, beam_search_stop=all max_input_length=150 nbest_size=1 ensemble_mode=None max_batch_size=32 dtype=torch.float32 skip_nvs=False nvs_thresh=0.5)
[2023-09-04:10:43:35:INFO:sockeye.translate:read_and_translate] Translating...
[2023-09-04:10:44:27:ERROR:root:exception_hook] Uncaught exception
Traceback (most recent call last):
  File "/home/dhanendra/anaconda3/bin/sockeye-translate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/dhanendra/anaconda3/lib/python3.11/site-packages/sockeye/translate.py", line 42, in main
    run_translate(args)
  File "/home/dhanendra/anaconda3/lib/python3.11/site-packages/sockeye/translate.py", line 146, in run_translate
    read_and_translate(translator=translator,
  File "/home/dhanendra/anaconda3/lib/python3.11/site-packages/sockeye/translate.py", line 232, in read_and_translate
    chunk_time = translate(output_handler, chunk, translator)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dhanendra/anaconda3/lib/python3.11/site-packages/sockeye/translate.py", line 255, in translate
    trans_outputs = translator.translate(trans_inputs)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dhanendra/anaconda3/lib/python3.11/site-packages/sockeye/inference.py", line 947, in translate
    batch_translations = self._translate_np(*self._get_inference_input(translator_inputs))
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dhanendra/anaconda3/lib/python3.11/site-packages/sockeye/inference.py", line 1193, in _translate_np
    return self._get_best_translations(self._search(source,
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/dhanendra/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dhanendra/anaconda3/lib/python3.11/site-packages/sockeye/beam_search.py", line 1060, in forward
    model_states = self._traced_sort_states(best_hyp_indices, *model_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dhanendra/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[2023-09-04:11:52:28:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.1.34, commit 4c30942ddb523533bccb4d2cbb3e894e45b1db93, path /home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/sockeye/__init__.py
[2023-09-04:11:52:28:INFO:sockeye.utils:log_torch_version] PyTorch: 1.13.1+cu117 (/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/torch/__init__.py)
[2023-09-04:11:52:28:INFO:sockeye.utils:log_basic_info] Command: /home/dhanendra/anaconda3/envs/iwslt-autodub/bin/sockeye-translate -i processed_datasets/de-text-noisy-durations0.1-en-phones-durations/test.de.json -o models/sockeye/trained_baselines/baseline_factored_noised0.1/eval/test.en.output --models models/sockeye/trained_baselines/baseline_factored_noised0.1/model --checkpoints 78 -b 5 --batch-size 32 --chunk-size 20000 --output-type translation_with_factors --max-output-length 768 --json-input --quiet
[2023-09-04:11:52:28:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(config=None, input='processed_datasets/de-text-noisy-durations0.1-en-phones-durations/test.de.json', input_factors=None, json_input=True, output='models/sockeye/trained_baselines/baseline_factored_noised0.1/eval/test.en.output', models=['models/sockeye/trained_baselines/baseline_factored_noised0.1/model'], checkpoints=[78], nbest_size=1, beam_size=5, greedy=False, beam_search_stop='all', batch_size=32, chunk_size=20000, sample=None, seed=None, ensemble_mode='linear', bucket_width=10, max_input_length=None, max_output_length_num_stds=2, max_output_length=768, restrict_lexicon=None, restrict_lexicon_topk=None, skip_nvs=False, nvs_thresh=0.5, strip_unknown_words=False, prevent_unk=False, output_type='translation_with_factors', length_penalty_alpha=1.0, length_penalty_beta=0.0, brevity_penalty_type='none', brevity_penalty_weight=1.0, brevity_penalty_constant_length_ratio=0.0, dtype=None, clamp_to_dtype=False, device_id=0, use_cpu=False, env=None, tf32=True, quiet=True, quiet_secondary_workers=False, no_logfile=False, loglevel='INFO', loglevel_secondary_workers='INFO', knn_index=None, knn_lambda=0.8)
[2023-09-04:11:52:28:INFO:sockeye.utils:init_device] CUDA not available, defaulting to CPU device
[2023-09-04:11:52:28:INFO:sockeye.translate:run_translate] Translate Device: cpu
[2023-09-04:11:52:28:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models/sockeye/trained_baselines/baseline_factored_noised0.1/model'] ...
[2023-09-04:11:52:28:INFO:sockeye.vocab:vocab_from_json] Vocabulary (10344 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.src.0.json"
[2023-09-04:11:52:28:INFO:sockeye.vocab:vocab_from_json] Vocabulary (80 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.0.json"
[2023-09-04:11:52:28:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.1.json"
[2023-09-04:11:52:28:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.2.json"
[2023-09-04:11:52:28:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.3.json"
[2023-09-04:11:52:28:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.4.json"
[2023-09-04:11:52:28:INFO:sockeye.model:load_model] Model version: 3.1.27
[2023-09-04:11:52:28:INFO:sockeye.model:load_config] Loaded model config from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/config"
[2023-09-04:11:52:28:INFO:sockeye.model:load_model] Disabling dropout layers for performance reasons
[2023-09-04:11:52:28:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=2890740, num_discarded=0, num_tokens_source=59369190, num_tokens_target=155336450, num_unks_source=0, num_unks_target=0, max_observed_len_source=94, max_observed_len_target=189, size_vocab_source=10344, size_vocab_target=80, length_ratio_mean=2.6285491632178375, length_ratio_std=0.5307655732772438, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (151, 152), (151, 160), (151, 168), (151, 176), (151, 184), (151, 192), (151, 200), (151, 201)], num_sents_per_bucket=[0, 22110, 135360, 246550, 350520, 403580, 430220, 432370, 393550, 273340, 135700, 50610, 13540, 2600, 320, 170, 80, 40, 40, 10, 20, 0, 0, 10, 0, 0], average_len_target_per_bucket=[None, 14.639077340569925, 21.061391843971673, 28.75895355911596, 36.678905625926355, 44.57116309034136, 52.536074566501156, 60.483960496795376, 68.38394104942114, 76.15284993048971, 83.90117907148164, 91.77376012645728, 99.63367799113755, 107.29230769230787, 115.21874999999991, 124.94117647058823, 132.62499999999997, 139.5, 147.24999999999997, 159.0, 165.0, None, None, 189.0, None, None], length_ratio_stats_per_bucket=[(None, None), (1.6336605602548555, 0.286261936883669), (1.9424967481218725, 0.34652802807048444), (2.2378038095453197, 0.3976252139444698), (2.440769792284621, 0.43440989413337183), (2.5843426768893876, 0.4541766109606066), (2.687728476890013, 0.47428305790760306), (2.7666510787767975, 0.48227906550526356), (2.8217258334504756, 0.48470162974307845), (2.8759974432299935, 0.49482087161470556), (2.933253154965025, 0.5004821684234914), (2.9835199293468997, 0.5201429624681303), (3.0325299451010497, 0.5067356869273223), (2.992097700547769, 0.48118416764844135), (2.9725602658980277, 0.531975485592598), (3.029502354582931, 0.6547038619502166), (3.2535635605818016, 0.4859033383112516), (3.475107493857494, 0.15279703105488074), (3.1417111847962915, 0.250628449935598), (3.3125, 0.0), (2.8999999999999995, 0.40000000000000013), (None, None), (None, None), (3.0, 0.0), (None, None), (None, None)]), max_seq_len_source=151, max_seq_len_target=201, num_source_factors=1, num_target_factors=5, eop_id=-1), vocab_source_size=10344, vocab_target_size=80, config_embed_source=EmbeddingConfig(vocab_size=10344, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=False), config_embed_target=EmbeddingConfig(vocab_size=80, num_embed=512, dropout=0.0, num_factors=5, factor_configs=[FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False), FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False), FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False), FactorConfig(vocab_size=9008, num_embed=32, combine='concat', share_embedding=False)], allow_sparse_grad=False), config_encoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=151, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=512, use_glu=False), config_decoder=TransformerConfig(model_size=736, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=151, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=512, use_glu=False), config_length_task=None, weight_tying_type='none', lhuc=False, dtype='float32', neural_vocab_selection=None, neural_vocab_selection_block_loss=False)
[2023-09-04:11:52:32:INFO:sockeye.model:load_parameters] Loaded params from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/params.00078" to "cpu"
[2023-09-04:11:52:32:INFO:sockeye.model:load_model] Model dtype: torch.float32
[2023-09-04:11:52:32:INFO:sockeye.model:load_models] 1 model(s) loaded in 4.0760s
[2023-09-04:11:52:32:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=5 algorithm=BeamSearch, beam_search_stop=all max_input_length=150 nbest_size=1 ensemble_mode=None max_batch_size=32 dtype=torch.float32 skip_nvs=False nvs_thresh=0.5)
[2023-09-04:11:52:32:INFO:sockeye.translate:read_and_translate] Translating...
[2023-09-04:11:53:16:ERROR:root:exception_hook] Uncaught exception
Traceback (most recent call last):
  File "/home/dhanendra/anaconda3/envs/iwslt-autodub/bin/sockeye-translate", line 8, in <module>
    sys.exit(main())
  File "/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/sockeye/translate.py", line 42, in main
    run_translate(args)
  File "/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/sockeye/translate.py", line 146, in run_translate
    read_and_translate(translator=translator,
  File "/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/sockeye/translate.py", line 232, in read_and_translate
    chunk_time = translate(output_handler, chunk, translator)
  File "/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/sockeye/translate.py", line 255, in translate
    trans_outputs = translator.translate(trans_inputs)
  File "/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/sockeye/inference.py", line 947, in translate
    batch_translations = self._translate_np(*self._get_inference_input(translator_inputs))
  File "/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/sockeye/inference.py", line 1193, in _translate_np
    return self._get_best_translations(self._search(source,
  File "/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/sockeye/beam_search.py", line 995, in forward
    target_dists, model_states, target_factors = self._inference.decode_step(best_word_indices,
  File "/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/sockeye/beam_search.py", line 88, in decode_step
    logits, knn_probs, states, target_factor_outputs = self._model.decode_step(step_input, states, vocab_slice_ids)
  File "/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/sockeye/model.py", line 317, in decode_step
    decode_step_outputs = self.traced_decode_step(*decode_step_inputs)
  File "/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
KeyboardInterrupt
[2023-09-04:13:49:53:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.1.34, commit 4c30942ddb523533bccb4d2cbb3e894e45b1db93, path /home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/sockeye/__init__.py
[2023-09-04:13:49:53:INFO:sockeye.utils:log_torch_version] PyTorch: 1.13.1+cu117 (/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/torch/__init__.py)
[2023-09-04:13:49:53:INFO:sockeye.utils:log_basic_info] Command: /home/dhanendra/anaconda3/envs/iwslt-autodub/bin/sockeye-translate -i processed_datasets/de-text-noisy-durations0.1-en-phones-durations/test.de.json -o models/sockeye/trained_baselines/baseline_factored_noised0.1/eval/test.en.output --models models/sockeye/trained_baselines/baseline_factored_noised0.1/model --checkpoints 78 -b 5 --batch-size 32 --chunk-size 20000 --output-type translation_with_factors --max-output-length 768 --json-input --quiet
[2023-09-04:13:49:53:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(config=None, input='processed_datasets/de-text-noisy-durations0.1-en-phones-durations/test.de.json', input_factors=None, json_input=True, output='models/sockeye/trained_baselines/baseline_factored_noised0.1/eval/test.en.output', models=['models/sockeye/trained_baselines/baseline_factored_noised0.1/model'], checkpoints=[78], nbest_size=1, beam_size=5, greedy=False, beam_search_stop='all', batch_size=32, chunk_size=20000, sample=None, seed=None, ensemble_mode='linear', bucket_width=10, max_input_length=None, max_output_length_num_stds=2, max_output_length=768, restrict_lexicon=None, restrict_lexicon_topk=None, skip_nvs=False, nvs_thresh=0.5, strip_unknown_words=False, prevent_unk=False, output_type='translation_with_factors', length_penalty_alpha=1.0, length_penalty_beta=0.0, brevity_penalty_type='none', brevity_penalty_weight=1.0, brevity_penalty_constant_length_ratio=0.0, dtype=None, clamp_to_dtype=False, device_id=0, use_cpu=False, env=None, tf32=True, quiet=True, quiet_secondary_workers=False, no_logfile=False, loglevel='INFO', loglevel_secondary_workers='INFO', knn_index=None, knn_lambda=0.8)
[2023-09-04:13:49:53:INFO:sockeye.utils:init_device] CUDA not available, defaulting to CPU device
[2023-09-04:13:49:53:INFO:sockeye.translate:run_translate] Translate Device: cpu
[2023-09-04:13:49:53:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models/sockeye/trained_baselines/baseline_factored_noised0.1/model'] ...
[2023-09-04:13:49:53:INFO:sockeye.vocab:vocab_from_json] Vocabulary (10344 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.src.0.json"
[2023-09-04:13:49:53:INFO:sockeye.vocab:vocab_from_json] Vocabulary (80 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.0.json"
[2023-09-04:13:49:53:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.1.json"
[2023-09-04:13:49:53:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.2.json"
[2023-09-04:13:49:53:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.3.json"
[2023-09-04:13:49:53:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.4.json"
[2023-09-04:13:49:53:INFO:sockeye.model:load_model] Model version: 3.1.27
[2023-09-04:13:49:53:INFO:sockeye.model:load_config] Loaded model config from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/config"
[2023-09-04:13:49:53:INFO:sockeye.model:load_model] Disabling dropout layers for performance reasons
[2023-09-04:13:49:53:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=2890740, num_discarded=0, num_tokens_source=59369190, num_tokens_target=155336450, num_unks_source=0, num_unks_target=0, max_observed_len_source=94, max_observed_len_target=189, size_vocab_source=10344, size_vocab_target=80, length_ratio_mean=2.6285491632178375, length_ratio_std=0.5307655732772438, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (151, 152), (151, 160), (151, 168), (151, 176), (151, 184), (151, 192), (151, 200), (151, 201)], num_sents_per_bucket=[0, 22110, 135360, 246550, 350520, 403580, 430220, 432370, 393550, 273340, 135700, 50610, 13540, 2600, 320, 170, 80, 40, 40, 10, 20, 0, 0, 10, 0, 0], average_len_target_per_bucket=[None, 14.639077340569925, 21.061391843971673, 28.75895355911596, 36.678905625926355, 44.57116309034136, 52.536074566501156, 60.483960496795376, 68.38394104942114, 76.15284993048971, 83.90117907148164, 91.77376012645728, 99.63367799113755, 107.29230769230787, 115.21874999999991, 124.94117647058823, 132.62499999999997, 139.5, 147.24999999999997, 159.0, 165.0, None, None, 189.0, None, None], length_ratio_stats_per_bucket=[(None, None), (1.6336605602548555, 0.286261936883669), (1.9424967481218725, 0.34652802807048444), (2.2378038095453197, 0.3976252139444698), (2.440769792284621, 0.43440989413337183), (2.5843426768893876, 0.4541766109606066), (2.687728476890013, 0.47428305790760306), (2.7666510787767975, 0.48227906550526356), (2.8217258334504756, 0.48470162974307845), (2.8759974432299935, 0.49482087161470556), (2.933253154965025, 0.5004821684234914), (2.9835199293468997, 0.5201429624681303), (3.0325299451010497, 0.5067356869273223), (2.992097700547769, 0.48118416764844135), (2.9725602658980277, 0.531975485592598), (3.029502354582931, 0.6547038619502166), (3.2535635605818016, 0.4859033383112516), (3.475107493857494, 0.15279703105488074), (3.1417111847962915, 0.250628449935598), (3.3125, 0.0), (2.8999999999999995, 0.40000000000000013), (None, None), (None, None), (3.0, 0.0), (None, None), (None, None)]), max_seq_len_source=151, max_seq_len_target=201, num_source_factors=1, num_target_factors=5, eop_id=-1), vocab_source_size=10344, vocab_target_size=80, config_embed_source=EmbeddingConfig(vocab_size=10344, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=False), config_embed_target=EmbeddingConfig(vocab_size=80, num_embed=512, dropout=0.0, num_factors=5, factor_configs=[FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False), FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False), FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False), FactorConfig(vocab_size=9008, num_embed=32, combine='concat', share_embedding=False)], allow_sparse_grad=False), config_encoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=151, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=512, use_glu=False), config_decoder=TransformerConfig(model_size=736, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=151, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=512, use_glu=False), config_length_task=None, weight_tying_type='none', lhuc=False, dtype='float32', neural_vocab_selection=None, neural_vocab_selection_block_loss=False)
[2023-09-04:13:49:57:INFO:sockeye.model:load_parameters] Loaded params from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/params.00078" to "cpu"
[2023-09-04:13:49:57:INFO:sockeye.model:load_model] Model dtype: torch.float32
[2023-09-04:13:49:58:INFO:sockeye.model:load_models] 1 model(s) loaded in 4.9165s
[2023-09-04:13:49:58:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=5 algorithm=BeamSearch, beam_search_stop=all max_input_length=150 nbest_size=1 ensemble_mode=None max_batch_size=32 dtype=torch.float32 skip_nvs=False nvs_thresh=0.5)
[2023-09-04:13:49:58:INFO:sockeye.translate:read_and_translate] Translating...
[2023-09-04:13:59:34:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.1.34, commit 4c30942ddb523533bccb4d2cbb3e894e45b1db93, path /home/dhanendra/anaconda3/envs/py37/lib/python3.7/site-packages/sockeye/__init__.py
[2023-09-04:13:59:34:INFO:sockeye.utils:log_torch_version] PyTorch: 1.13.1+cu117 (/home/dhanendra/anaconda3/envs/py37/lib/python3.7/site-packages/torch/__init__.py)
[2023-09-04:13:59:34:INFO:sockeye.utils:log_basic_info] Command: /home/dhanendra/anaconda3/envs/py37/bin/sockeye-translate -i processed_datasets/de-text-noisy-durations0.1-en-phones-durations/test.de.json -o models/sockeye/trained_baselines/baseline_factored_noised0.1/eval/test.en.output --models models/sockeye/trained_baselines/baseline_factored_noised0.1/model --checkpoints 78 -b 5 --batch-size 32 --chunk-size 20000 --output-type translation_with_factors --max-output-length 768 --json-input --quiet
[2023-09-04:13:59:34:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(batch_size=32, beam_search_stop='all', beam_size=5, brevity_penalty_constant_length_ratio=0.0, brevity_penalty_type='none', brevity_penalty_weight=1.0, bucket_width=10, checkpoints=[78], chunk_size=20000, clamp_to_dtype=False, config=None, device_id=0, dtype=None, ensemble_mode='linear', env=None, greedy=False, input='processed_datasets/de-text-noisy-durations0.1-en-phones-durations/test.de.json', input_factors=None, json_input=True, knn_index=None, knn_lambda=0.8, length_penalty_alpha=1.0, length_penalty_beta=0.0, loglevel='INFO', loglevel_secondary_workers='INFO', max_input_length=None, max_output_length=768, max_output_length_num_stds=2, models=['models/sockeye/trained_baselines/baseline_factored_noised0.1/model'], nbest_size=1, no_logfile=False, nvs_thresh=0.5, output='models/sockeye/trained_baselines/baseline_factored_noised0.1/eval/test.en.output', output_type='translation_with_factors', prevent_unk=False, quiet=True, quiet_secondary_workers=False, restrict_lexicon=None, restrict_lexicon_topk=None, sample=None, seed=None, skip_nvs=False, strip_unknown_words=False, tf32=True, use_cpu=False)
[2023-09-04:13:59:34:INFO:sockeye.utils:init_device] CUDA not available, defaulting to CPU device
[2023-09-04:13:59:34:INFO:sockeye.translate:run_translate] Translate Device: cpu
[2023-09-04:13:59:34:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models/sockeye/trained_baselines/baseline_factored_noised0.1/model'] ...
[2023-09-04:13:59:35:INFO:sockeye.vocab:vocab_from_json] Vocabulary (10344 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.src.0.json"
[2023-09-04:13:59:35:INFO:sockeye.vocab:vocab_from_json] Vocabulary (80 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.0.json"
[2023-09-04:13:59:35:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.1.json"
[2023-09-04:13:59:35:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.2.json"
[2023-09-04:13:59:35:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.3.json"
[2023-09-04:13:59:35:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.4.json"
[2023-09-04:13:59:35:INFO:sockeye.model:load_model] Model version: 3.1.27
[2023-09-04:13:59:35:INFO:sockeye.model:load_config] Loaded model config from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/config"
[2023-09-04:13:59:35:INFO:sockeye.model:load_model] Disabling dropout layers for performance reasons
[2023-09-04:13:59:35:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=2890740, num_discarded=0, num_tokens_source=59369190, num_tokens_target=155336450, num_unks_source=0, num_unks_target=0, max_observed_len_source=94, max_observed_len_target=189, size_vocab_source=10344, size_vocab_target=80, length_ratio_mean=2.6285491632178375, length_ratio_std=0.5307655732772438, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (151, 152), (151, 160), (151, 168), (151, 176), (151, 184), (151, 192), (151, 200), (151, 201)], num_sents_per_bucket=[0, 22110, 135360, 246550, 350520, 403580, 430220, 432370, 393550, 273340, 135700, 50610, 13540, 2600, 320, 170, 80, 40, 40, 10, 20, 0, 0, 10, 0, 0], average_len_target_per_bucket=[None, 14.639077340569925, 21.061391843971673, 28.75895355911596, 36.678905625926355, 44.57116309034136, 52.536074566501156, 60.483960496795376, 68.38394104942114, 76.15284993048971, 83.90117907148164, 91.77376012645728, 99.63367799113755, 107.29230769230787, 115.21874999999991, 124.94117647058823, 132.62499999999997, 139.5, 147.24999999999997, 159.0, 165.0, None, None, 189.0, None, None], length_ratio_stats_per_bucket=[(None, None), (1.6336605602548555, 0.286261936883669), (1.9424967481218725, 0.34652802807048444), (2.2378038095453197, 0.3976252139444698), (2.440769792284621, 0.43440989413337183), (2.5843426768893876, 0.4541766109606066), (2.687728476890013, 0.47428305790760306), (2.7666510787767975, 0.48227906550526356), (2.8217258334504756, 0.48470162974307845), (2.8759974432299935, 0.49482087161470556), (2.933253154965025, 0.5004821684234914), (2.9835199293468997, 0.5201429624681303), (3.0325299451010497, 0.5067356869273223), (2.992097700547769, 0.48118416764844135), (2.9725602658980277, 0.531975485592598), (3.029502354582931, 0.6547038619502166), (3.2535635605818016, 0.4859033383112516), (3.475107493857494, 0.15279703105488074), (3.1417111847962915, 0.250628449935598), (3.3125, 0.0), (2.8999999999999995, 0.40000000000000013), (None, None), (None, None), (3.0, 0.0), (None, None), (None, None)]), max_seq_len_source=151, max_seq_len_target=201, num_source_factors=1, num_target_factors=5, eop_id=-1), vocab_source_size=10344, vocab_target_size=80, config_embed_source=EmbeddingConfig(vocab_size=10344, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=False), config_embed_target=EmbeddingConfig(vocab_size=80, num_embed=512, dropout=0.0, num_factors=5, factor_configs=[FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False), FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False), FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False), FactorConfig(vocab_size=9008, num_embed=32, combine='concat', share_embedding=False)], allow_sparse_grad=False), config_encoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=151, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=512, use_glu=False), config_decoder=TransformerConfig(model_size=736, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=151, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=512, use_glu=False), config_length_task=None, weight_tying_type='none', lhuc=False, dtype='float32', neural_vocab_selection=None, neural_vocab_selection_block_loss=False)
[2023-09-04:13:59:40:INFO:sockeye.model:load_parameters] Loaded params from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/params.00078" to "cpu"
[2023-09-04:13:59:40:INFO:sockeye.model:load_model] Model dtype: torch.float32
[2023-09-04:13:59:40:INFO:sockeye.model:load_models] 1 model(s) loaded in 5.2217s
[2023-09-04:13:59:40:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=5 algorithm=BeamSearch, beam_search_stop=all max_input_length=150 nbest_size=1 ensemble_mode=None max_batch_size=32 dtype=torch.float32 skip_nvs=False nvs_thresh=0.5)
[2023-09-04:13:59:40:INFO:sockeye.translate:read_and_translate] Translating...
[2023-09-04:19:24:40:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.1.32, commit unknown, path /home/dhanendra/sockeye/sockeye/__init__.py
[2023-09-04:19:24:40:INFO:sockeye.utils:log_torch_version] PyTorch: 1.13.1+cu117 (/home/dhanendra/anaconda3/envs/iwslt-autodub/lib/python3.9/site-packages/torch/__init__.py)
[2023-09-04:19:24:40:INFO:sockeye.utils:log_basic_info] Command: /home/dhanendra/anaconda3/envs/iwslt-autodub/bin/sockeye-translate -i processed_datasets/de-text-noisy-durations0.1-en-phones-durations/test.de.json -o models/sockeye/trained_baselines/baseline_factored_noised0.1/eval/test.en.output --models models/sockeye/trained_baselines/baseline_factored_noised0.1/model --checkpoints 78 -b 5 --batch-size 32 --chunk-size 20000 --output-type translation_with_factors --max-output-length 768 --force-factors-stepwise frames total_remaining segment_remaining pauses_remaining --json-input --quiet
[2023-09-04:19:24:40:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(config=None, input='processed_datasets/de-text-noisy-durations0.1-en-phones-durations/test.de.json', input_factors=None, json_input=True, output='models/sockeye/trained_baselines/baseline_factored_noised0.1/eval/test.en.output', models=['models/sockeye/trained_baselines/baseline_factored_noised0.1/model'], checkpoints=[78], nbest_size=1, beam_size=5, greedy=False, beam_search_stop='all', batch_size=32, chunk_size=20000, sample=None, seed=None, ensemble_mode='linear', bucket_width=10, max_input_length=None, max_output_length_num_stds=2, max_output_length=768, restrict_lexicon=None, restrict_lexicon_topk=None, skip_nvs=False, nvs_thresh=0.5, strip_unknown_words=False, prevent_unk=False, output_type='translation_with_factors', length_penalty_alpha=1.0, length_penalty_beta=0.0, brevity_penalty_type='none', brevity_penalty_weight=1.0, brevity_penalty_constant_length_ratio=0.0, force_factors_stepwise=['frames', 'total_remaining', 'segment_remaining', 'pauses_remaining'], pause_symbol='[pause]', eow_symbol='<eow>', dtype=None, clamp_to_dtype=False, device_id=0, use_cpu=False, env=None, tf32=True, quiet=True, quiet_secondary_workers=False, no_logfile=False, loglevel='INFO', loglevel_secondary_workers='INFO', knn_index=None, knn_lambda=0.8)
[2023-09-04:19:24:40:INFO:sockeye.utils:init_device] CUDA not available, defaulting to CPU device
[2023-09-04:19:24:40:INFO:sockeye.translate:run_translate] Translate Device: cpu
[2023-09-04:19:24:40:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models/sockeye/trained_baselines/baseline_factored_noised0.1/model'] ...
[2023-09-04:19:24:40:INFO:sockeye.vocab:vocab_from_json] Vocabulary (10344 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.src.0.json"
[2023-09-04:19:24:40:INFO:sockeye.vocab:vocab_from_json] Vocabulary (80 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.0.json"
[2023-09-04:19:24:40:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.1.json"
[2023-09-04:19:24:40:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.2.json"
[2023-09-04:19:24:40:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.3.json"
[2023-09-04:19:24:40:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9008 words) loaded from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/vocab.trg.4.json"
[2023-09-04:19:24:40:INFO:sockeye.model:load_model] Model version: 3.1.27
[2023-09-04:19:24:40:INFO:sockeye.model:load_config] Loaded model config from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/config"
[2023-09-04:19:24:40:INFO:sockeye.model:load_model] Disabling dropout layers for performance reasons
[2023-09-04:19:24:40:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=2890740, num_discarded=0, num_tokens_source=59369190, num_tokens_target=155336450, num_unks_source=0, num_unks_target=0, max_observed_len_source=94, max_observed_len_target=189, size_vocab_source=10344, size_vocab_target=80, length_ratio_mean=2.6285491632178375, length_ratio_std=0.5307655732772438, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (151, 152), (151, 160), (151, 168), (151, 176), (151, 184), (151, 192), (151, 200), (151, 201)], num_sents_per_bucket=[0, 22110, 135360, 246550, 350520, 403580, 430220, 432370, 393550, 273340, 135700, 50610, 13540, 2600, 320, 170, 80, 40, 40, 10, 20, 0, 0, 10, 0, 0], average_len_target_per_bucket=[None, 14.639077340569925, 21.061391843971673, 28.75895355911596, 36.678905625926355, 44.57116309034136, 52.536074566501156, 60.483960496795376, 68.38394104942114, 76.15284993048971, 83.90117907148164, 91.77376012645728, 99.63367799113755, 107.29230769230787, 115.21874999999991, 124.94117647058823, 132.62499999999997, 139.5, 147.24999999999997, 159.0, 165.0, None, None, 189.0, None, None], length_ratio_stats_per_bucket=[(None, None), (1.6336605602548555, 0.286261936883669), (1.9424967481218725, 0.34652802807048444), (2.2378038095453197, 0.3976252139444698), (2.440769792284621, 0.43440989413337183), (2.5843426768893876, 0.4541766109606066), (2.687728476890013, 0.47428305790760306), (2.7666510787767975, 0.48227906550526356), (2.8217258334504756, 0.48470162974307845), (2.8759974432299935, 0.49482087161470556), (2.933253154965025, 0.5004821684234914), (2.9835199293468997, 0.5201429624681303), (3.0325299451010497, 0.5067356869273223), (2.992097700547769, 0.48118416764844135), (2.9725602658980277, 0.531975485592598), (3.029502354582931, 0.6547038619502166), (3.2535635605818016, 0.4859033383112516), (3.475107493857494, 0.15279703105488074), (3.1417111847962915, 0.250628449935598), (3.3125, 0.0), (2.8999999999999995, 0.40000000000000013), (None, None), (None, None), (3.0, 0.0), (None, None), (None, None)]), max_seq_len_source=151, max_seq_len_target=201, num_source_factors=1, num_target_factors=5), vocab_source_size=10344, vocab_target_size=80, config_embed_source=EmbeddingConfig(vocab_size=10344, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=False), config_embed_target=EmbeddingConfig(vocab_size=80, num_embed=512, dropout=0.0, num_factors=5, factor_configs=[FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False, embed_type='learned'), FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False, embed_type='learned'), FactorConfig(vocab_size=9008, num_embed=64, combine='concat', share_embedding=False, embed_type='learned'), FactorConfig(vocab_size=9008, num_embed=32, combine='concat', share_embedding=False, embed_type='learned')], allow_sparse_grad=False), config_encoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=151, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_decoder=TransformerConfig(model_size=736, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=151, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_length_task=None, weight_tying_type='none', lhuc=False, dtype='float32', neural_vocab_selection=None, neural_vocab_selection_block_loss=False)
[2023-09-04:19:24:45:INFO:sockeye.model:load_parameters] Loaded params from "models/sockeye/trained_baselines/baseline_factored_noised0.1/model/params.00078" to "cpu"
[2023-09-04:19:24:45:INFO:sockeye.model:load_model] Model dtype: torch.float32
[2023-09-04:19:24:45:INFO:sockeye.model:load_models] 1 model(s) loaded in 5.1162s
[2023-09-04:19:24:45:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=5 algorithm=BeamSearch, beam_search_stop=all max_input_length=150 nbest_size=1 ensemble_mode=None max_batch_size=32 dtype=torch.float32 skip_nvs=False nvs_thresh=0.5 force_factors_stepwise=['frames', 'total_remaining', 'segment_remaining', 'pauses_remaining'])
[2023-09-04:19:24:45:INFO:sockeye.translate:read_and_translate] Translating...
[2023-09-04:22:58:05:INFO:sockeye.translate:read_and_translate] Processed 15373 lines. Total time: 12799.6060, sec/sent: 0.8326, sent/sec: 1.2011
